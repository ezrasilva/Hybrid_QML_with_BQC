{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visão Geral e Objetivo do Notebook**\n",
    "\n",
    "Este notebook demonstra uma implementação de **Blind Quantum Computing (BQC)**, um paradigma que permite a um cliente (Alice) executar um algoritmo quântico em um servidor quântico remoto (Bob) sem revelar informações sobre o algoritmo ou os dados.\n",
    "\n",
    "Para isso, o código utiliza um **Classificador Quântico Variacional (VQC)**, um modelo de Machine Learning híbrido quântico-clássico. O objetivo é classificar o famoso dataset Iris (com 3 classes) enquanto simula o processo de envio do circuito quântico a uma rede a cada época de treinamento, mimetizando um cenário de BQC.\n",
    "\n",
    "As principais tecnologias utilizadas são:\n",
    "* **Qiskit:** Para a construção dos circuitos quânticos e a definição do modelo de Machine Learning.\n",
    "* **Qiskit Aer:** Para simular a execução do circuito em um backend com ruído, tornando o ambiente mais realista.\n",
    "* **Scikit-learn:** Para o pré-processamento dos dados e o cálculo das métricas de avaliação.\n",
    "* **Quantumnet:** Uma biblioteca customizada para simular a topologia de rede e a transmissão do circuito, abstraindo a complexidade do BQC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 1: Importações e Configuração Inicial**\n",
    "\n",
    "Nesta primeira célula de código, realizamos duas tarefas essenciais:\n",
    "\n",
    "1.  **Instalação de Dependências:** O comando `!pip install` garante que todas as bibliotecas necessárias (qiskit, qiskit-aer, qiskit-machine-learning, qiskit-algorithms, scikit-learn e numpy) estejam instaladas no ambiente de execução.\n",
    "\n",
    "2.  **Importação de Módulos:** Em seguida, importamos as classes e funções específicas que serão usadas ao longo do código. Isso inclui ferramentas para construir circuitos (`QuantumCircuit`, `ZFeatureMap`) e modelos de Machine Learning (`EstimatorQNN`, `NeuralNetworkClassifier`), bem como utilitários para processamento de dados (`load_iris`, `MinMaxScaler`) e a biblioteca `quantumnet` para a simulação de BQC.\n",
    "\n",
    "Finalmente, uma semente de aleatoriedade (`SEED = 42`) é definida para `random` e `numpy`. Isso é crucial para garantir que os resultados sejam reproduzíveis; ou seja, sempre que o código for executado, a divisão dos dados e a inicialização dos pesos aleatórios serão as mesmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1: Importações e Configuração\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Importações do Qiskit\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import ZFeatureMap, RealAmplitudes\n",
    "from qiskit_aer.primitives import Estimator as AerEstimator\n",
    "from qiskit_aer.noise import NoiseModel, depolarizing_error\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "from qiskit_machine_learning.utils.loss_functions import CrossEntropyLoss\n",
    "from qiskit_algorithms.optimizers import SPSA\n",
    "\n",
    "# Importações do Scikit-learn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Importação da biblioteca BQC (assumindo que está em um módulo chamado 'quantumnet')\n",
    "# from quantumnet.components import Network, Logger\n",
    "\n",
    "# Semente para reprodutibilidade\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 2: Preparação do Dataset Iris**\n",
    "\n",
    "O sucesso de qualquer modelo de Machine Learning começa com um bom tratamento dos dados. Nesta seção, o dataset Iris é preparado para ser utilizado pelo classificador quântico.\n",
    "\n",
    "1.  **Carregamento:** `load_iris()` carrega o conjunto de dados, que contém informações sobre três espécies de flores Iris (setosa, versicolor e virginica) com base em quatro características (comprimento e largura da sépala e da pétala).\n",
    "\n",
    "2.  **Normalização (Scaling):** As características (`X`) são redimensionadas para um intervalo entre 0 e 1 usando o `MinMaxScaler`. Este passo é fundamental para algoritmos quânticos, pois os parâmetros dos circuitos (como ângulos de rotação) operam em uma escala bem definida.\n",
    "\n",
    "3.  **Codificação One-Hot:** O VQC que será construído produzirá uma saída para cada classe. Para comparar a previsão com o rótulo real, os rótulos de saída (`y`) são convertidos de um único número (0, 1 ou 2) para um formato vetorial, onde apenas a classe correta é marcada com '1' (ex: a classe 2 se torna `[0, 0, 1]`). Isso é feito pelo `OneHotEncoder`.\n",
    "\n",
    "4.  **Divisão em Treino e Teste:** Os dados são divididos em um conjunto de treinamento (usado para ensinar o modelo) e um conjunto de teste (usado para avaliar seu desempenho em dados nunca vistos), utilizando a função `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2: Preparação dos Dados (3 Classes)\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)\n",
    "\n",
    "# Codificar rótulos com One-Hot\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = encoder.fit_transform(y)\n",
    "\n",
    "# Normalizar as características\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_onehot, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "print(f\"Dados preparados para classificação multiclasse ({y_onehot.shape[1]} classes) com {X_train.shape[1]} features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 3: Configuração do Backend com Ruído**\n",
    "\n",
    "Computadores quânticos reais são suscetíveis a ruídos do ambiente, que podem causar erros nos cálculos. Para tornar a simulação mais próxima da realidade, configuramos um backend quântico simulado que imita esse comportamento.\n",
    "\n",
    "1.  **Criação do Modelo de Ruído:** Um `NoiseModel` é instanciado. Nele, adicionamos um `depolarizing_error` (erro de despolarização), que é um tipo comum de ruído quântico. Definimos uma taxa de erro de 1% para portas de um único qubit (`error_1q`) e 2% para portas de dois qubits (`error_2q`).\n",
    "\n",
    "2.  **Aplicação do Ruído:** O modelo de ruído é configurado para aplicar esses erros a portas quânticas específicas (`'rz'`, `'sx'`, `'x'` e `'cx'`).\n",
    "\n",
    "3.  **Criação do Estimador Ruidoso:** O `AerEstimator` é o simulador do Qiskit que executará os circuitos. Nós o configuramos para usar o `noise_model` criado, garantindo que todas as execuções daqui para frente incluam os efeitos do ruído. As `run_options` definem que cada \"tiro\" (shot) do circuito será repetido 1024 vezes para obter uma estatística robusta do resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 3: Configuração do Backend com Ruído\n",
    "print(\"\\nConfigurando o simulador com modelo de ruído...\")\n",
    "noise_model = NoiseModel()\n",
    "error_1q = depolarizing_error(0.01, 1)\n",
    "error_2q = depolarizing_error(0.02, 2)\n",
    "\n",
    "# Adicionar erros a portas específicas\n",
    "noise_model.add_all_qubit_quantum_error(error_1q, ['rz', 'sx', 'x'])\n",
    "noise_model.add_all_qubit_quantum_error(error_2q, ['cx'])\n",
    "\n",
    "# Criar o estimador ruidoso\n",
    "noisy_estimator = AerEstimator(\n",
    "    backend_options={\"noise_model\": noise_model},\n",
    "    run_options={\"seed\": SEED, \"shots\": 1024},\n",
    "    transpile_options={\"seed_transpiler\": SEED},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 4: Construção do Modelo Quântico (VQC)**\n",
    "\n",
    "Aqui, montamos a arquitetura do nosso modelo de rede neural quântica. Ele é composto por um circuito quântico parametrizado e observáveis para extrair os resultados.\n",
    "\n",
    "1.  **Feature Map (Mapa de Características):** O `ZFeatureMap` é a primeira parte do circuito. Sua função é codificar os dados clássicos de entrada (as 4 características das flores Iris) nos estados dos qubits.\n",
    "\n",
    "2.  **Ansatz:** O `RealAmplitudes` é a segunda parte do circuito. Este é o componente \"treinável\" do modelo. Ele consiste em uma sequência de portas quânticas cujos parâmetros (ângulos de rotação) serão ajustados durante o treinamento pelo otimizador clássico para minimizar a função de perda. O argumento `reps=3` define a profundidade (ou complexidade) deste circuito.\n",
    "\n",
    "3.  **Observáveis:** Para um problema de classificação com 3 classes, precisamos de 3 saídas. Os `observables` (`SparsePauliOp`) definem como os qubits serão medidos para produzir essas saídas. Aqui, medimos o operador Pauli Z em cada um dos três primeiros qubits, o que nos dará um valor esperado que será usado como a \"ativação\" da rede para cada classe.\n",
    "\n",
    "4.  **EstimatorQNN:** Finalmente, o `EstimatorQNN` une todas as peças: o circuito (`qc`), os observáveis, a definição de quais parâmetros são da entrada (`input_params`) e quais são os pesos treináveis (`weight_params`), e o simulador com ruído (`noisy_estimator`). Ele representa a nossa rede neural quântica completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 4: Construção do Modelo Quântico\n",
    "num_qubits = X_train.shape[1]\n",
    "feature_map = ZFeatureMap(num_qubits)\n",
    "ansatz = RealAmplitudes(num_qubits, reps=3)\n",
    "\n",
    "# Combinar feature map e ansatz em um único circuito\n",
    "qc = QuantumCircuit(num_qubits)\n",
    "qc.compose(feature_map, inplace=True)\n",
    "qc.compose(ansatz, inplace=True)\n",
    "\n",
    "# Definir observáveis para as 3 classes\n",
    "observables = [\n",
    "    SparsePauliOp(\"ZIII\"),\n",
    "    SparsePauliOp(\"IZII\"),\n",
    "    SparsePauliOp(\"IIZI\")\n",
    "]\n",
    "\n",
    "# Criar a Rede Neural Quântica\n",
    "qnn = EstimatorQNN(\n",
    "    circuit=qc,\n",
    "    observables=observables,\n",
    "    input_params=feature_map.parameters,\n",
    "    weight_params=ansatz.parameters,\n",
    "    estimator=noisy_estimator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 5: Simulação de Rede BQC e Função de Callback**\n",
    "\n",
    "Esta é a seção central que simula o paradigma de **Blind Quantum Computing (BQC)**. A ideia é que, a cada passo do treinamento, o circuito com os pesos atualizados é \"enviado\" para uma rede remota para execução.\n",
    "\n",
    "1.  **Inicialização da Rede (Conceitual):** O código original usa uma classe `Network` customizada. Para este notebook de propósito geral, definiremos uma função de espaço reservado. Em um cenário real de BQC, este passo inicializaria a conexão com o servidor quântico.\n",
    "\n",
    "2.  **Função de Callback `simulacao_callback_bqc`:**\n",
    "    * Um \"callback\" é uma função que é passada como argumento para outra e é executada automaticamente em um determinado momento.\n",
    "    * Esta função foi projetada para ser chamada **ao final de cada época** do processo de treinamento do VQC.\n",
    "    * Dentro dela, simulamos o processo de envio do circuito. Ela imprime a perda (loss) atual e o número da época, mimetizando a comunicação que ocorreria em um protocolo BQC real. Ela não executa o circuito para obter resultados (isso é trabalho do `EstimatorQNN`), mas sim simula a transmissão segura e privada do experimento a cada iteração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 5: Simulação de Rede BQC e Definição do Callback\n",
    "print(\"\\nDefinindo o callback para a simulação de BQC...\")\n",
    "\n",
    "# Este é um espaço reservado para a inicialização da rede do notebook original.\n",
    "# Em um cenário real, isso configuraria as conexões de rede.\n",
    "# rede = Network()\n",
    "# rede.set_ready_topology('grade', 8, 3, 3)\n",
    "# Logger.activate(Logger)\n",
    "\n",
    "# Definir a função de callback\n",
    "def simulacao_callback_bqc(weights, loss):\n",
    "    \"\"\"\n",
    "    Esta função é chamada a cada passo do otimizador.\n",
    "    Ela simula o envio do circuito com os pesos atuais para uma rede BQC.\n",
    "    O 'passo' é gerenciado externamente pelo mecanismo de callback do classificador.\n",
    "    \"\"\"\n",
    "    # Usamos uma variável global ou de classe para rastrear a época, se necessário,\n",
    "    # já que a assinatura básica do callback é apenas (weights, loss).\n",
    "    global contador_epoca\n",
    "    print(f\"\\n[Época {contador_epoca+1}] Loss: {loss:.4f} - Simulando envio do circuito para a rede...\")\n",
    "    \n",
    "    # Em uma implementação real, você construiria e enviaria o circuito:\n",
    "    # current_circuit = feature_map.compose(ansatz.assign_parameters(weights))\n",
    "    # try:\n",
    "    #     rede.application_layer.run_app(...)\n",
    "    #     print(f\"[Época {contador_epoca+1}] Simulação de envio concluída.\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"[Época {contador_epoca+1}] Erro ao enviar circuito: {str(e)}\")\n",
    "    print(f\"[Época {contador_epoca+1}] Simulação de envio concluída.\")\n",
    "    contador_epoca += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 6: Treinamento do Classificador VQC**\n",
    "\n",
    "Com todos os componentes prontos, iniciamos o treinamento do modelo.\n",
    "\n",
    "1.  **Otimizador SPSA:** O `SPSA` (Simultaneous Perturbation Stochastic Approximation) é um otimizador clássico especialmente eficiente para ambientes ruidosos, como o de computadores quânticos. Ele ajusta os pesos do *ansatz* para minimizar a função de perda. O número de iterações (`maxiter`) foi limitado a 100, pois a simulação completa (incluindo o callback) é computacionalmente intensiva.\n",
    "\n",
    "2.  **NeuralNetworkClassifier:** Esta é a classe do Qiskit que gerencia todo o processo de treinamento. Nós a instanciamos com:\n",
    "    * `neural_network=qnn`: Nosso modelo quântico.\n",
    "    * `optimizer=optimizer`: O otimizador SPSA.\n",
    "    * `loss=CrossEntropyLoss()`: Uma função de perda padrão para problemas de classificação multiclasse.\n",
    "    * `callback=simulacao_callback_bqc`: **O ponto-chave**. Passamos nossa função de callback aqui. Agora, a cada passo que o SPSA der para otimizar os pesos, a função será chamada, imprimindo o *loss* e simulando o envio do circuito.\n",
    "\n",
    "3.  **Execução do Treinamento:** A linha `vqc.fit(X_train, y_train)` inicia o loop de treinamento. O classificador começa a alimentar o modelo com os dados de treino, calcular a perda e usar o otimizador para ajustar os pesos, chamando o callback a cada passo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 6: Treinamento com Callback de BQC\n",
    "print(\"\\nTREINANDO O VQC COM RUÍDO E CALLBACK DE BQC...\")\n",
    "optimizer = SPSA(maxiter=100) # Menos iterações pois a simulação pode ser lenta\n",
    "\n",
    "# Inicializar contador de época para o callback\n",
    "contador_epoca = 0\n",
    "\n",
    "# Passar a função de callback para o classificador\n",
    "vqc = NeuralNetworkClassifier(\n",
    "    neural_network=qnn,\n",
    "    optimizer=optimizer,\n",
    "    loss=CrossEntropyLoss(),\n",
    "    one_hot=True,\n",
    "    callback=simulacao_callback_bqc # A função é passada aqui\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "vqc.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "print(f\"\\nTreinamento concluído em {end_time - start_time:.2f} segundos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parte 7: Avaliação do Modelo e Métricas Finais**\n",
    "\n",
    "Após o treinamento, é crucial avaliar o quão bem o nosso modelo VQC se generaliza para dados que ele nunca viu antes (o conjunto de teste).\n",
    "\n",
    "1.  **Previsão:** O método `vqc.predict(X_test)` usa o modelo treinado para fazer previsões no conjunto de teste. O resultado (`y_pred_onehot`) está no formato one-hot.\n",
    "\n",
    "2.  **Decodificação:** Para calcular as métricas, os rótulos previstos e os rótulos de teste verdadeiros são convertidos de volta do formato one-hot para o formato de rótulo único (0, 1 ou 2) usando `np.argmax`.\n",
    "\n",
    "3.  **Cálculo de Métricas:** São calculadas quatro métricas de classificação padrão:\n",
    "    * **Acurácia:** Percentual de previsões corretas.\n",
    "    * **Precisão:** Dentre todas as vezes que o modelo previu uma classe, quantas estavam corretas.\n",
    "    * **Recall:** Dentre todas as instâncias reais de uma classe, quantas o modelo conseguiu identificar.\n",
    "    * **F1 Score:** Média harmônica entre precisão e recall, útil para dados desbalanceados.\n",
    "\n",
    "4.  **Matriz de Confusão:** Por fim, a `confusion_matrix` é gerada e exibida. Ela é uma tabela que visualiza o desempenho do classificador, mostrando os acertos e os erros para cada classe. Por exemplo, ela mostra quantas vezes a classe \"setosa\" foi classificada corretamente e quantas vezes foi confundida com \"versicolor\" ou \"virginica\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 7: Avaliação do Modelo\n",
    "print(\"\\nCALCULANDO MÉTRICAS DE CLASSIFICAÇÃO...\")\n",
    "y_pred_onehot = vqc.predict(X_test)\n",
    "\n",
    "# Decodificar previsões one-hot\n",
    "y_pred_labels = np.argmax(y_pred_onehot, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "precision = precision_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\nMÉTRICAS FINAIS:\")\n",
    "print(f\"Acurácia : {accuracy:.4f}\")\n",
    "print(f\"Precisão : {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# Exibir matriz de confusão\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris.target_names)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}